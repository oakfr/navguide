Navguide is a set of algorithms for vision-based navigation using uncalibrated cameras. Navguide builds upon a topological representation of the environment and requires no intrinsic or extrinsic camera calibration.

Navguide was developed at the Massachusetts Institute of Technology Computer Science and Artificial Intelligence Laboratory (MIT CSAIL) by [Olivier Koch](http://people.csail.mit.edu/koch) and [Seth Teller](http://people.csail.mit.edu/teller).

### Main features ###

  * Topological mapping

  * Global localization using recursive Bayesian filtering

  * Vision-based loop closure using a vocabulary tree

  * Rotation guidance based on statistical learning of point feature matches across cameras


### References ###

  * Ground Robot Navigation using Uncalibrated Cameras, O. Koch, M. Walter,
A. Huang, S. Teller, _International Conference on Robotics and Automation
(ICRA)_, Anchorage, Alaska, 2010.

  * Body Relative Navigation using Uncalibrated Cameras, O. Koch, S. Teller,
_International Conference on Computer Vision (ICCV)_, Kyoto, Japan, 2009.
